\section{Introduction}

This short chapter presents new preimage attacks for the \shaone hash function.
The results are obtained by extending the differential view of \mitm preimage attacks with higher-order differentials.

\medskip

The starting point of the work described here is the \mitm technique, which
was first used in cryptography by Diffie and Hellman in 1977 to attack double-encryption~\cite{DH77}.
Its use for preimage attack is much more recent and is due to Aoki and Sasaki, who used it as a framework to
attack various hash functions, including for instance SHA-0 and \shaone~\cite{AS09}.
The basic principle behind a \mitm technique is to exploit the fact that some intermediate value of
a function's computation can be expressed
in two different ways involving different parts of a secret, which can then be sampled independently of
each other. In the case of hash function cryptanalysis, there is no actual secret to consider, but a
similar technique can nonetheless be exploited in certain cases; we show in more details how to do
so in the preliminaries of~\autoref{KKFramework}.

At CRYPTO~2012, Knellwolf and Khovratovich introduced a differential formulation of the \mitm framework
of Aoki and Sasaki, which they used to improve the best attacks on \shaone~\cite{DBLP:conf/crypto/KnellwolfK12}. One of the main interests
of their approach is that it simplifies the formulation of several advanced extensions of
the \mitm technique, and thereby facilitates the search for attack parameters, which in the case
of \mitm attacks roughly correspond to good partitions for the ``secret''.

In this chapter, we further exploit this differential formulation and generalise it to use higher-order
differentials, which were introduced in cryptography by Lai in 1994~\cite{L94}. The essence
of this technique is to consider ``standard'' differential cryptanalysis as exploiting properties
of the first-order derivative of the function one wishes to analyse; it is then somehow natural
to generalise the idea and to consider higher-order derivatives as well. We illustrate this
with a small example using XOR differences: consider a function $\Fs$ and
assume the equality $\Delta_\alpha\Fs(x) \defas \Fs(x) \oplus \Fs(x \oplus \alpha) = A$ holds with a good probability
over the values of $x$; this
is the same as saying that the derivative of $\Fs$ in $\alpha$ is biased towards $A$. In an extreme case,
if $\Fs$ is linear, then $\Delta_\alpha\Fs$ is constantly equal to $\Fs(\alpha)$.
%, though this is obviously not true in general.
Now if we consider the expression $\Delta_\alpha\Fs(x) \oplus \Delta_\alpha\Fs(x \oplus \beta) =
\Fs(x) \oplus \Fs(x \oplus \alpha) \oplus \Fs(x \oplus \beta)
\oplus \Fs(x \oplus \alpha \oplus \beta)$, this corresponds to taking the derivative of $\Fs$ twice,
first
in $\alpha$, and then in $\beta$. A possible advantage of doing this is that the resulting function may be more
biased than $\Delta_\alpha\Fs$ was, for instance by being constant when $\Delta_\alpha\Fs$ is linear.
This process can be iterated at will, each time decreasing the algebraic degree of the resulting
function until it reaches zero.

As higher-order differentials are obviously best formulated in differential form,
they combine neatly with the differential view of the framework of Knellwolf and Khovratovich, whereas
using a similar technique in a \mitm attack independently of any differential formulation would probably prove to be
much more difficult.
As a final motivation for this generalisation, we show a small application to
the analysis of the \mdfour hash function~\cite{Rivest-md4}. This does not improve the best known
preimage attacks~\cite{md4p2,md4p3}, but gives a good illustration of the potential of the technique.

\paragraph{Higher-order differentials for the compression function of \mdfour.}

The inverse of the state update function inside the compression function of \mdfour is of
the form: $q_{i-4} \leftarrow (q_i \circlearrowleft s_i) - \boolF(q_{i-1}, q_{i-2}, q_{i-3}) - m_j$,
with
the subtraction being done modulo $2^{32}$.
Four consecutive steps of this inverse function can thus be written as:
\[
q_3 \leftarrow (q_7 \circlearrowleft s_7) - \boolF(q_6, q_5, q_4) - m_7
\]
\[
q_2 \leftarrow (q_6 \circlearrowleft s_6) - \boolF(q_5, q_4, q_3) - m_6
\]
\[
q_1 \leftarrow (q_6 \circlearrowleft s_5) - \boolF(q_4, q_3, q_2) - m_5
\]
\[
q_0 \leftarrow (q_4 \circlearrowleft s_4) - \boolF(q_3, q_2, q_1) - m_4
\]

If we consider order-2 differentials on $m_6$ and $m_7$, with 
additive differences modulo $2^{32}$ concentrated around
the most significant bit, that is of the form $\onediff\onediff\onediff\onediff\nodiff\nodiff\nodiff\nodiff$,
computing the state update from above on these differences results in
a state $q_{0\ldots3}$ with differences of the form:

\medskip

\begin{tabular}{l l l l l l}
\phantom{toto}$q_3^\ddagger$: & \dunnodiff\dunnodiff\dunnodiff\dunnodiff\nodiff\nodiff\nodiff\nodiff & \phantom{toto} $q_3^\star$: &
\nodiff\nodiff\nodiff\nodiff\nodiff\nodiff\nodiff\nodiff & \phantom{toto} $q_3^\dagger$:  & equal to $q_3^\ddagger$ \\
\phantom{toto}$q_2^\ddagger$: & \dunnodiff\dunnodiff\dunnodiff\dunnodiff\nodiff\nodiff\nodiff\nodiff & \phantom{toto} $q_2^\star$: &
\dunnodiff\dunnodiff\dunnodiff\dunnodiff\nodiff\nodiff\nodiff\nodiff     & \phantom{toto} $q_2^\dagger$:  & \dunnodiff\dunnodiff\dunnodiff\dunnodiff\nodiff\nodiff\nodiff\nodiff \\
\phantom{toto}$q_1^\ddagger$: & \dunnodiff\dunnodiff\dunnodiff\dunnodiff\nodiff\nodiff\nodiff\nodiff & \phantom{toto} $q_1^\star$: &
\dunnodiff\dunnodiff\dunnodiff\dunnodiff\nodiff\nodiff\nodiff\nodiff     & \phantom{toto} $q_1^\dagger$:  & \dunnodiff\dunnodiff\dunnodiff\dunnodiff\nodiff\nodiff\nodiff\nodiff \\
\phantom{toto}$q_0^\ddagger$: & \dunnodiff\dunnodiff\dunnodiff\dunnodiff\nodiff\nodiff\nodiff\nodiff & \phantom{toto} $q_0^\star$: &
\dunnodiff\dunnodiff\dunnodiff\dunnodiff\nodiff\nodiff\nodiff\nodiff     & \phantom{toto} $q_0^\dagger$:  & \dunnodiff\dunnodiff\dunnodiff\dunnodiff\nodiff\nodiff\nodiff\nodiff \\
\end{tabular}

\smallskip

\begin{tabular}{l l l}
\phantom{toto} For diff. on $m_7$ & \phantom{toto} For diff. on $m_6$ & \phantom{toto} For diff. on $m_6$ \& $m_7$\\
\end{tabular}

Thus there is no difference on the value $q_3^\dagger - q_3^\star - q_3^\ddagger + q_3$, and
the differences on the remaining words also have a high probability. This good differential behaviour
can then be exploited in a later attack.

It is worth noting that in the very case of \mdfour, one could also use very
good local collisions from order-1 message differences, and higher-order differentials do not typically outperform these; we just
gave them for illustration.

\subsection{Previous and new results on \shaone}
The first preimage attacks on \shaone were due to De~Canni\`ere and Rechberger~\cite{DBLP:conf/crypto/CanniereR08},
who used a system-based approach that in particular allows to compute practical preimages for a non-trivial
number of steps. In order to attack more steps, Aoki and Sasaki later used a \mitm approach~\cite{AS09}.
This was subsequently improved by Knellwolf and Khovratovich~\cite{DBLP:conf/crypto/KnellwolfK12}, who attacked the highest number
of rounds so far. To be more precise,
they attack reduced versions of the function up to 52 steps for \emph{one-block preimages with padding},
57 steps for \emph{one-block preimages without padding}, and 60 steps for \emph{one-block pseudo-preimages
with padding}, \ie freestart preimages with padding. The latter two attacks can be combined to give 57 steps \emph{two-block preimages with padding}.
In this work, we present \emph{one-block preimages with padding} up to 56 steps,
\emph{one-block preimages without padding} up to 62 steps, \emph{one-block pseudo preimages with padding} up
to 64 steps, resulting in \emph{two-block preimages with padding} up to 62 steps.

We give a summary of these results in \autoref{tbl:res}.

\begin{table}[!htb]
\caption[Existing and new preimage attacks on \shaone.]{Existing and new preimage attacks on \shaone, with complexity given in base-2 logarithm.\label{tbl:res}}
\begin{center}
\begin{tabularx}{\textwidth}{@{\extracolsep{2mm} } l c c X  X}
\toprule
Function & \# blocks & \# rounds &  complexity &  ref.\\
\toprule
 \multirow{6}{*}{\shaone} & 1 & 52 & 158.4 & \cite{DBLP:conf/crypto/KnellwolfK12} \\
 & 1 & 52 & 156.7 & \autoref{sec:one_wi_pad} \\
 & 1 & 56 & 159.4 & \autoref{sec:one_wi_pad} \\
 & 2 & 57 & 158.8 & \cite{DBLP:conf/crypto/KnellwolfK12} \\
 & 2 & 58 & 157.9 & \autoref{sec:one_two} \\
 & 2 & 62 & 159.3 & \autoref{sec:one_two} \\
\midrule
\multirow{3}{*}{\shaone, without padding} & 1 & 57 & 158.7 & \cite{DBLP:conf/crypto/KnellwolfK12} \\
 & 1 & 58 & 157.4 & \autoref{sec:one_wo_pad} \\
 & 1 & 62 & 159 & \autoref{sec:one_wo_pad} \\
\midrule
\multirow{3}{*}{\shaone, pseudo-preimage} & 1 & 60 & 157.4 & \cite{DBLP:conf/crypto/KnellwolfK12} \\
 & 1 & 61 & 156.4 & \autoref{sec:one_two} \\
 & 1 & 64 & 158.7 & \autoref{sec:one_two} \\
\bottomrule
\end{tabularx}

\end{center}
\end{table}
